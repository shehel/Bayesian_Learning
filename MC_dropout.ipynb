{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MC Dropout\n",
    "Following [this](https://arxiv.org/pdf/1506.02142.pdf) paper to implement MC dropout to get uncertainty from deep NNs using Tensorflow and MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-01T18:20:32.227381Z",
     "start_time": "2018-04-01T18:20:30.634226Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-01T18:22:49.046055Z",
     "start_time": "2018-04-01T18:22:48.520802Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-01T18:22:53.741887Z",
     "start_time": "2018-04-01T18:22:53.734966Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = mnist.train.images\n",
    "y = mnist.train.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-01T07:24:46.806388Z",
     "start_time": "2018-04-01T07:24:46.800974Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train, X_test, y, y_test = train_test_split(\n",
    "#     X_train, y, test_size=0.995, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-01T18:20:52.158774Z",
     "start_time": "2018-04-01T18:20:52.144167Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-01T18:22:55.887881Z",
     "start_time": "2018-04-01T18:22:55.884859Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = mnist.test.images\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-01T18:22:56.978226Z",
     "start_time": "2018-04-01T18:22:56.972076Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = X_train.shape[0]\n",
    "\n",
    "#Possible output labels\n",
    "K = 10\n",
    "#Batch size\n",
    "M = 128\n",
    "#Size of hidden units\n",
    "H= 1024\n",
    "#Number of initial convolution features\n",
    "U= 16\n",
    "#Dimension of input to FC layer\n",
    "D = 7*7*(U*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-01T18:22:57.357829Z",
     "start_time": "2018-04-01T18:22:57.346750Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(arrays, batch_size):\n",
    "  \"\"\"Generate batches, one with respect to each array's first axis.\"\"\"\n",
    "  starts = [0] * len(arrays)  # pointers to where we are in iteration\n",
    "  while True:\n",
    "    batches = []\n",
    "    for i, array in enumerate(arrays):\n",
    "      start = starts[i]\n",
    "      stop = start + batch_size\n",
    "      diff = stop - array.shape[0]\n",
    "      if diff <= 0:\n",
    "        batch = array[start:stop]\n",
    "        starts[i] += batch_size\n",
    "      else:\n",
    "        batch = np.concatenate((array[start:], array[:diff]))\n",
    "        starts[i] = diff\n",
    "      batches.append(batch)\n",
    "    yield batches\n",
    "data = generator([X_train, y], M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-01T18:22:58.253510Z",
     "start_time": "2018-04-01T18:22:58.234884Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Placeholders\n",
    "x_p = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_p = tf.placeholder(tf.int64, shape=[None])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "keep_probc = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-01T18:22:58.719332Z",
     "start_time": "2018-04-01T18:22:58.712105Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-01T18:22:59.321842Z",
     "start_time": "2018-04-01T18:22:59.076503Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Model parameters\n",
    "Wconv1 = weight([5, 5, 1, U])\n",
    "bconv1 = bias([U])\n",
    "Wconv2 = weight([5, 5, U, U*2])\n",
    "bconv2 = bias([U*2])\n",
    "\n",
    "W0 = weight([D, H])\n",
    "b0 = bias([H])\n",
    "W1 = weight([H, K])\n",
    "b1 = bias([K])\n",
    "\n",
    "#Model\n",
    "x = tf.reshape(x_p, [-1,28,28,1])\n",
    "x = tf.nn.dropout(x, keep_probc)\n",
    "\n",
    "x = tf.nn.tanh(conv2d(x, Wconv1) + bconv1)\n",
    "#x = tf.nn.dropout(x, keep_probc)\n",
    "\n",
    "x = max_pool_2x2(x)\n",
    "x = tf.nn.dropout(x, keep_probc)\n",
    "\n",
    "x = tf.nn.tanh(conv2d(x, Wconv2) + bconv2)\n",
    "#x = tf.nn.dropout(x, keep_probc)\n",
    "\n",
    "x = max_pool_2x2(x)\n",
    "x = tf.nn.dropout(x, keep_probc)\n",
    "\n",
    "x = tf.reshape(x, [-1, D])\n",
    "x = tf.nn.tanh(tf.matmul(x, W0) + b0)\n",
    "x = tf.nn.dropout(x, keep_prob)\n",
    "\n",
    "output = tf.nn.softmax(tf.matmul(x, W1) + b1)\n",
    "\n",
    "cross_entropy =-tf.reduce_sum(tf.one_hot(y_p, 10)*tf.log(output))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(output,1), y_p)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-01T18:22:59.969931Z",
     "start_time": "2018-04-01T18:22:59.964578Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_batch = int(N / M)\n",
    "n_epoch = 30\n",
    "iters = n_batch*n_epoch\n",
    "dropout = 0.5\n",
    "dropoutc = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-01T18:23:37.068112Z",
     "start_time": "2018-04-01T18:23:01.068700Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(iters):\n",
    "  X_batch, y_batch = next(data)\n",
    "  if i%100 == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict={\n",
    "        x_p:X_batch, y_p: y_batch, keep_prob: dropout, keep_probc:dropoutc})\n",
    "    print(\"step %d, training accuracy %g\"%(i, train_accuracy), end=\"\\r\", flush=True)\n",
    "  train_step.run(feed_dict={x_p: X_batch, y_p: y_batch, keep_prob: dropout, keep_probc:dropoutc})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-01T18:25:18.485865Z",
     "start_time": "2018-04-01T18:25:18.366475Z"
    }
   },
   "outputs": [],
   "source": [
    "#Accuracy without MC dropout\n",
    "feed_dict = feed_dict={\n",
    "    x_p: mnist.test.images, keep_prob: dropout, keep_probc:dropoutc}\n",
    "pred =output.eval(feed_dict)\n",
    "y_pred = np.argmax(pred,axis=1)\n",
    "print(\" Accuracy on test set= \", (y_pred == y_test).mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-01T18:25:24.326428Z",
     "start_time": "2018-04-01T18:25:22.063534Z"
    }
   },
   "outputs": [],
   "source": [
    "n_samples = 50\n",
    "pred_lst = []\n",
    "feed_dict = feed_dict={\n",
    "    x_p: mnist.test.images, keep_prob: dropout, keep_probc:dropoutc}\n",
    "for _ in tqdm(range(n_samples)):\n",
    "    pred =output.eval(feed_dict)\n",
    "    pred_lst.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-01T18:25:25.754741Z",
     "start_time": "2018-04-01T18:25:25.621533Z"
    }
   },
   "outputs": [],
   "source": [
    "accy_test = []\n",
    "for pred in pred_lst:\n",
    "    y_trn_prd = np.argmax(pred,axis=1).astype(np.float32)\n",
    "    acc = (y_trn_prd == y_test).mean()*100\n",
    "    accy_test.append(acc)\n",
    "\n",
    "plt.hist(accy_test)\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-01T18:25:28.620423Z",
     "start_time": "2018-04-01T18:25:28.611396Z"
    }
   },
   "outputs": [],
   "source": [
    "#Model Averaging\n",
    "y_pred = np.argmax(np.mean(pred_lst,axis=0),axis=1)\n",
    "print(\" Accuracy on test set= \", (y_pred == y_test).mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-01T18:26:19.445866Z",
     "start_time": "2018-04-01T18:26:19.356173Z"
    }
   },
   "outputs": [],
   "source": [
    "test_ind = 74\n",
    "\n",
    "test_image = X_test[test_ind]\n",
    "test_label = y_test[test_ind]\n",
    "print('truth = ',test_label)\n",
    "pixels = test_image.reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-01T18:26:26.313171Z",
     "start_time": "2018-04-01T18:26:26.296932Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_preds = []\n",
    "for pred in pred_lst:\n",
    "    y_trn_prd = np.argmax(pred,axis=1).astype(np.float32)\n",
    "    acc = y_trn_prd[test_ind]\n",
    "    img_preds.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-01T18:26:26.708068Z",
     "start_time": "2018-04-01T18:26:26.643369Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist((img_preds),bins=range(11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
